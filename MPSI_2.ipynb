{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNTDbmjH6wonsMbl1KVrz/+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kvazzzzar/MPSI/blob/main/MPSI_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Импорт библиотек**"
      ],
      "metadata": {
        "id": "rAXHnFhh39ka"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymorphy3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "coRMXwY32onI",
        "outputId": "2b71d3ab-b2fe-49cd-a784-46e4ff8dd333"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pymorphy3 in /usr/local/lib/python3.11/dist-packages (2.0.3)\n",
            "Requirement already satisfied: dawg2-python>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from pymorphy3) (0.9.0)\n",
            "Requirement already satisfied: pymorphy3-dicts-ru in /usr/local/lib/python3.11/dist-packages (from pymorphy3) (2.4.417150.4580142)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pymorphy3\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etlaIBIQ3X4K",
        "outputId": "86ab0783-1b5b-4fa6-d5ad-14f72b9881b5"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Пример текста**"
      ],
      "metadata": {
        "id": "3-gjsCZE4CtU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = [\n",
        "    \"Туман клубится над рекой\",\n",
        "    \"Где тени древних сосен спят\",\n",
        "    \"Вода хранит покой глухой\",\n",
        "    \"И лунный свет в волнах дрожит\",\n",
        "\n",
        "    \"Камни, поросшие травой\",\n",
        "    \"Шепчут забытые слова\",\n",
        "    \"Ветер несёт голос ночной\",\n",
        "    \"О том, что время не властно тут\",\n",
        "\n",
        "    \"Огонь костра мерцает в тьме\",\n",
        "    \"Рисуя лики на скале\",\n",
        "    \"И звёзды падают к земле\",\n",
        "    \"Как искры древней на груде\"\n",
        "]"
      ],
      "metadata": {
        "id": "3zC4RPW835tw"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Функция предобработки (лемматизация + удаление стоп-слов)**"
      ],
      "metadata": {
        "id": "x5VNIHx74rU-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "morph = pymorphy3.MorphAnalyzer()\n",
        "stop_words = set(stopwords.words('russian'))\n",
        "\n",
        "def clean_text(texts):\n",
        "    result = []\n",
        "    for text in texts:\n",
        "        # Токенизация\n",
        "        words = word_tokenize(text.lower())\n",
        "        # Лемматизация и фильтрация\n",
        "        clean_words = [\n",
        "            morph.parse(word)[0].normal_form\n",
        "            for word in words\n",
        "            if word.isalpha() and word not in stop_words\n",
        "        ]\n",
        "        result.append(clean_words)\n",
        "    return result"
      ],
      "metadata": {
        "id": "A5BXXpTP4Evh"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned = clean_text(text)\n",
        "for i, text in enumerate(cleaned):\n",
        "    print(f\"Текст {i+1}: {text}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2E3KWWf4Fzq",
        "outputId": "a30a7fc3-0b05-41db-bfd2-05f4eda14467"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Текст 1: ['туман', 'клубиться', 'река']\n",
            "Текст 2: ['тень', 'древний', 'сосна', 'спать']\n",
            "Текст 3: ['вода', 'хранить', 'покой', 'глухой']\n",
            "Текст 4: ['лунный', 'свет', 'волна', 'дрожать']\n",
            "Текст 5: ['камень', 'порасти', 'трава']\n",
            "Текст 6: ['шептать', 'забытый', 'слово']\n",
            "Текст 7: ['ветер', 'нести', 'голос', 'ночной']\n",
            "Текст 8: ['время', 'властно']\n",
            "Текст 9: ['огонь', 'костёр', 'мерцать', 'тьма']\n",
            "Текст 10: ['рисовать', 'лик', 'скала']\n",
            "Текст 11: ['звезда', 'падать', 'земля']\n",
            "Текст 12: ['искра', 'древний', 'груда']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Bag of Words**"
      ],
      "metadata": {
        "id": "rW0ld3Gq4dt4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def bag_of_words(texts):\n",
        "    # Получаем все уникальные слова\n",
        "    all_words = set(word for text in texts for word in text)\n",
        "    vocabulary = {word: i for i, word in enumerate(sorted(all_words))}\n",
        "\n",
        "    # Создаем векторы\n",
        "    vectors = []\n",
        "    for text in texts:\n",
        "        vector = [0] * len(vocabulary)\n",
        "        for word in text:\n",
        "            if word in vocabulary:\n",
        "                vector[vocabulary[word]] += 1\n",
        "        vectors.append(vector)\n",
        "\n",
        "    return vocabulary, vectors\n",
        "\n",
        "vocab, bow_vectors = bag_of_words(cleaned)\n",
        "print(\"\\nСловарь:\", vocab)\n",
        "print(\"Векторы BoW:\")\n",
        "for vec in bow_vectors:\n",
        "    print(vec)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKTfYOaJ4Rj2",
        "outputId": "7182afc7-a632-42b7-c0b9-2fb0e7cdd95d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Словарь: {'ветер': 0, 'властно': 1, 'вода': 2, 'волна': 3, 'время': 4, 'глухой': 5, 'голос': 6, 'груда': 7, 'древний': 8, 'дрожать': 9, 'забытый': 10, 'звезда': 11, 'земля': 12, 'искра': 13, 'камень': 14, 'клубиться': 15, 'костёр': 16, 'лик': 17, 'лунный': 18, 'мерцать': 19, 'нести': 20, 'ночной': 21, 'огонь': 22, 'падать': 23, 'покой': 24, 'порасти': 25, 'река': 26, 'рисовать': 27, 'свет': 28, 'скала': 29, 'слово': 30, 'сосна': 31, 'спать': 32, 'тень': 33, 'трава': 34, 'туман': 35, 'тьма': 36, 'хранить': 37, 'шептать': 38}\n",
            "Векторы BoW:\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0]\n",
            "[0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
            "[0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "[1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TF-IDF**"
      ],
      "metadata": {
        "id": "t066ZX3S40IP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tf_idf(texts):\n",
        "    # Сначала получаем BoW представление\n",
        "    vocab, bow_vectors = bag_of_words(texts)\n",
        "    num_docs = len(texts)\n",
        "\n",
        "    # Считаем IDF для каждого слова\n",
        "    idf = {}\n",
        "    for word in vocab:\n",
        "        docs_with_word = sum(1 for vec in bow_vectors if vec[vocab[word]] > 0)\n",
        "        idf[word] = math.log(num_docs / docs_with_word)\n",
        "\n",
        "    # Считаем TF-IDF\n",
        "    tfidf_vectors = []\n",
        "    for vec in bow_vectors:\n",
        "        tfidf = [count * idf[word] for word, count in zip(vocab, vec)]\n",
        "        tfidf_vectors.append(tfidf)\n",
        "\n",
        "    return vocab, tfidf_vectors\n",
        "\n",
        "vocab, tfidf_vectors = tf_idf(cleaned)\n",
        "print(\"\\nTF-IDF векторы:\")\n",
        "for vec in tfidf_vectors:\n",
        "    print(vec)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNQATEc551pz",
        "outputId": "a08d3918-2019-4e42-8fd6-df483342e80b"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TF-IDF векторы:\n",
            "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4849066497880004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4849066497880004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4849066497880004, 0.0, 0.0, 0.0]\n",
            "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.791759469228055, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4849066497880004, 2.4849066497880004, 2.4849066497880004, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "[0.0, 0.0, 2.4849066497880004, 0.0, 0.0, 2.4849066497880004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4849066497880004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4849066497880004, 0.0]\n",
            "[0.0, 0.0, 0.0, 2.4849066497880004, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4849066497880004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4849066497880004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4849066497880004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4849066497880004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4849066497880004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4849066497880004, 0.0, 0.0, 0.0, 0.0]\n",
            "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4849066497880004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4849066497880004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4849066497880004]\n",
            "[2.4849066497880004, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4849066497880004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4849066497880004, 2.4849066497880004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "[0.0, 2.4849066497880004, 0.0, 0.0, 2.4849066497880004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4849066497880004, 0.0, 0.0, 2.4849066497880004, 0.0, 0.0, 2.4849066497880004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4849066497880004, 0.0, 0.0]\n",
            "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4849066497880004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4849066497880004, 0.0, 2.4849066497880004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4849066497880004, 2.4849066497880004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4849066497880004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4849066497880004, 1.791759469228055, 0.0, 0.0, 0.0, 0.0, 2.4849066497880004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bag of Words:**\n",
        "\n",
        "Словарь из 39 лемматизированных слов отражает основные темы:\n",
        "\n",
        "Природа: \"туман\", \"река\", \"сосна\"\n",
        "\n",
        "Мистика: \"тень\", \"древний\", \"тьма\"\n",
        "\n",
        "**Векторы показывают:**\n",
        "\n",
        "Каждая строка содержит 2-4 значимых слова\n",
        "\n",
        "Наибольшая частота у \"древний\" (3), \"огонь\" (2)\n",
        "\n",
        "Уникальные слова: \"властно\", \"груда\", \"искра\" (по 1 разу)\n",
        "\n",
        "**TF-IDF:**\n",
        "\n",
        "Выделяет наиболее значимые слова:\n",
        "\n",
        "Максимальные значения (2.48) у редких слов: \"туман\", \"река\", \"костёр\"\n",
        "\n",
        "Средние значения (1.79) у умеренно частых: \"древний\", \"груда\"\n",
        "\n",
        "**Лучше BoW показывает:**\n",
        "\n",
        "Уникальные образы (\"лунный свет\")\n",
        "\n",
        "Ключевые тематические слова (\"забытый\", \"слово\")\n",
        "\n",
        "**Вывод:**\n",
        "\n",
        "Оба метода подтверждают поэтическую лаконичность текста (2-4 значимых слова на строку). TF-IDF эффективнее выделяет редкие, но важные для смысла слова, в то время как BoW лучше показывает общую частотную структуру.\n",
        "\n"
      ],
      "metadata": {
        "id": "_iJc92i853m6"
      }
    }
  ]
}